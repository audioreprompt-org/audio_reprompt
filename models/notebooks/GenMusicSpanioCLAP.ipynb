{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fffeb50b",
   "metadata": {},
   "source": [
    "# Generar piezas musicales con el dataset de Spanio üéµ\n",
    "\n",
    "Utilizar los pesos de music_audioset_epoch_15_esc_90.14.pt en lugar de los gen√©ricos que carga clap_model.load_ckpt() para verificar si hay una mejor√≠a en el CLAP Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d10406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juana/.venv311/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from laion_clap import CLAP_Module\n",
    "from torch import serialization\n",
    "from tqdm import tqdm\n",
    "\n",
    "import laion_clap.clap_module.factory as factory\n",
    "import laion_clap.hook as hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37f25df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Ra√≠z del proyecto: /home/juana/audio_reprompt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Detectar la ra√≠z del proyecto autom√°ticamente\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "for parent in [PROJECT_ROOT, *PROJECT_ROOT.parents]:\n",
    "    if (parent / \"models\" / \"scripts\" / \"types.py\").exists():\n",
    "        PROJECT_ROOT = parent\n",
    "        break\n",
    "\n",
    "# Agregar la ra√≠z al sys.path si no est√°\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(\"üîç Ra√≠z del proyecto:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0b4b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.scripts.types import MusicGenCLAPResult, MusicGenData\n",
    "from config import load_config, setup_project_paths, PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451a5e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Dispositivo: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c0f03cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurando las rutas del proyecto...\n",
      "Cargando configuraci√≥n...\n"
     ]
    }
   ],
   "source": [
    "print(\"Configurando las rutas del proyecto...\")\n",
    "setup_project_paths()\n",
    "\n",
    "print(\"Cargando configuraci√≥n...\")\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad8f75df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_base_data_path = PROJECT_ROOT / config.data.tracks_base_data_path\n",
    "data_clap_path = (\n",
    "    PROJECT_ROOT / config.data.data_clap_path / \"results_with_clap_weights.csv\"\n",
    ")\n",
    "\n",
    "laion_clap_path = PROJECT_ROOT / config.model.laion_clap_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932957a7",
   "metadata": {},
   "source": [
    "### Calcular el CLAP Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1794f14",
   "metadata": {},
   "source": [
    "`CLAP_Module`:\n",
    "\n",
    "Es un wrapper del modelo CLAP que permite el uso del modelo CLAP para obtener embeddings de audio y texto, calcular similitudes o entrenar nuevos modelos multimodales.\n",
    "\n",
    "Par√°metro:\n",
    "\n",
    "- `enable_fusion`: activa o desactiva un mecanismo interno del modelo CLAP que combina informaci√≥n de audio y texto en una representaci√≥n conjunta, es decir, un embedding fusionado. Esto permite calcular de forma directa una similitud entre embeddings audio ‚Üî texto, sin necesidad de entrenar un modelo adicional. Si es False, el modelo cargar√≠a solo el codificador de audio o texto, sin capacidad de comparar entre ellos, por lo que el c√°lculo de similitud coseno no tendr√≠a sentido.\n",
    "\n",
    "F√≥rmula de la similitud del coseno:\n",
    "\n",
    "$$\n",
    "\\text{sim}(a, b) = \\frac{a \\cdot b}{\\|a\\| \\|b\\|}\n",
    "$$\n",
    "\n",
    "El resultado (score) es un n√∫mero entre -1 y 1:\n",
    "\n",
    "- +1 ‚Üí audio y texto son muy similares.\n",
    "\n",
    "- 0 ‚Üí no hay relaci√≥n.\n",
    "\n",
    "- -1 ‚Üí son opuestos sem√°nticamente (raro en pr√°ctica).\n",
    "\n",
    "¬øPor qu√© en CLAP casi nunca salen negativos?\n",
    "\n",
    "El modelo CLAP fue entrenado con una p√©rdida contrastiva tipo InfoNCE que:\n",
    "\n",
    "- Maximiza la similitud entre los pares correctos (audio ‚Üî descripci√≥n) \n",
    "- Minimiza la similitud entre los pares incorrectos.\n",
    "\n",
    "El modelo nunca vio ejemplos de ‚Äúoposici√≥n sem√°ntica‚Äù (como ‚Äúsilencio‚Äù vs ‚Äúexplosi√≥n‚Äù) durante el entrenamiento, por eso, el coseno rara vez llega a valores extremos (‚àí1 o 1).\n",
    "\n",
    "Por lo tanto, tras el entrenamiento:\n",
    "\n",
    "| Tipo de relaci√≥n audio-texto | CLAP Score t√≠pico |\n",
    "| ---------------------------- | ----------------- |\n",
    "| Muy alta coherencia          | 0.7 ‚Äì 0.9         |\n",
    "| Moderada coherencia          | 0.4 ‚Äì 0.6         |\n",
    "| Poca coherencia              | 0.2 ‚Äì 0.4         |\n",
    "| Ruido o sin relaci√≥n         | < 0.2             |\n",
    "\n",
    "[Ver referencia de clap score](https://arxiv.org/html/2506.23553v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc5c75",
   "metadata": {},
   "source": [
    "#### Funciones para utilizar otros pesos con Clap Score\n",
    "\n",
    "El modelo CLAP (Contrastive Language-Audio Pretraining) tiene m√∫ltiples variantes entrenadas en distintos datasets:\n",
    "\n",
    "| Alias            | Modelo base real    | Dataset                 | Uso principal            |\n",
    "| ---------------- | ------------------- | ----------------------- | ------------------------ |\n",
    "| `music_audioset` | `HTSAT-base`        | AudioSet + ESC-50       | M√∫sica y sonidos         |\n",
    "| `HTSAT-base`     | Transformer HTSAT   | Audio feature extractor | Base de ‚Äúmusic_audioset‚Äù |\n",
    "| `roberta-base`   | Transformer textual | Text encoder            | Texto de prompts         |\n",
    "\n",
    "\n",
    "El checkpoint music_audioset_epoch_15_esc_90.14.pt fue entrenado sobre la arquitectura HTSAT-base (audio encoder) + roberta-base (text encoder), pero el c√≥digo original del paquete laion_clap no reconoce ‚Äúmusic_audioset‚Äù como un nombre de modelo v√°lido.\n",
    "\n",
    "¬øPor qu√© no poner directamente HTSAT-base?\n",
    "\n",
    "Porque el nombre music_audioset no es solo un alias cosm√©tico, sino que est√° ligado al tipo de checkpoint y la arquitectura que CLAP espera internamente.\n",
    "\n",
    "- HTSAT-base es un modelo de audio gen√©rico.\n",
    "\n",
    "- music_audioset es una versi√≥n fine-tuned (ajustada) de HTSAT-base + text encoder (RoBERTa) sobre el dataset AudioSet + ESC-50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba08c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parche aplicado: CLAP_Module ahora reconoce 'music_audioset' como alias de 'HTSAT-base'\n",
      "Patch aplicado: factory.load_state_dict modificado para carga segura y completa de pesos.\n",
      "Aplicando parche de compatibilidad: np.random.integers -> np.random.randint\n"
     ]
    }
   ],
   "source": [
    "def patched_create_model(amodel_name: str, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Intercepta la llamada que crea el modelo y reemplaza el identificador \"music_audioset\" por \n",
    "    \"HTSAT-base\" antes de que el c√≥digo interno lo procese.\n",
    "    \"\"\"\n",
    "    if amodel_name == \"music_audioset\":\n",
    "        print(\"üéµ Usando modelo 'music_audioset' (alias de HTSAT-base)\")\n",
    "        amodel_name = \"HTSAT-base\"\n",
    "    return (\n",
    "        factory._create_model(amodel_name, *args, **kwargs)\n",
    "        if hasattr(factory, \"_create_model\")\n",
    "        else factory.create_model(amodel_name, *args, **kwargs)\n",
    "    )\n",
    "\n",
    "\n",
    "# Guardar referencia al original.\n",
    "factory._create_model = getattr(factory, \"create_model\", None)\n",
    "\n",
    "# Reemplazar en ambos lugares.\n",
    "factory.create_model = patched_create_model\n",
    "hook.create_model = patched_create_model\n",
    "\n",
    "print(\n",
    "    \"Parche aplicado: CLAP_Module ahora reconoce 'music_audioset' como alias de 'HTSAT-base'\"\n",
    ")\n",
    "\n",
    "\n",
    "def patched_load_state_dict(checkpoint_path, map_location=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Modifica c√≥mo se cargan los pesos (state_dict) del checkpoint.\n",
    "    \n",
    "    Patches factory.load_state_dict:\n",
    "    1. Resuelve el error de seguridad (numpy global).\n",
    "    2. Asegura que NO se salten los par√°metros ('skip_params=False' impl√≠cito)\n",
    "       para que se carguen los pesos de audio (HTSAT) y texto (RoBERTa).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define los globals requeridos por el checkpoint.\n",
    "    safe_globals = [\"numpy.core.multiarray.scalar\"]\n",
    "\n",
    "    print(\n",
    "        f\"‚úÖ Aplicando parche de seguridad para cargar el checkpoint: {checkpoint_path}\"\n",
    "    )\n",
    "\n",
    "    # 1. Usar el context manager para permitir los globals.\n",
    "    # 2. Usar weights_only=False, como sugiere el error de PyTorch.\n",
    "    with serialization.safe_globals(safe_globals):\n",
    "        # Cargar el archivo de checkpoint completo.\n",
    "        checkpoint = torch.load(\n",
    "            checkpoint_path, map_location=map_location, weights_only=False\n",
    "        )\n",
    "\n",
    "    # Extraer el 'state_dict'. La mayor√≠a de los checkpoints de PyTorch guardan los pesos aqu√≠.\n",
    "    if isinstance(checkpoint, dict) and \"state_dict\" in checkpoint:\n",
    "        state_dict = checkpoint[\"state_dict\"]\n",
    "    else:\n",
    "        # Si el checkpoint es solo el state_dict.\n",
    "        state_dict = checkpoint\n",
    "\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "factory.load_state_dict = patched_load_state_dict\n",
    "print(\n",
    "    \"Patch aplicado: factory.load_state_dict modificado para carga segura y completa de pesos.\"\n",
    ")\n",
    "\n",
    "if not hasattr(np.random, \"integers\"):\n",
    "    \"\"\" \n",
    "    Crea un alias integers ‚Üí randint.\n",
    "    \"\"\"\n",
    "    print(\"Aplicando parche de compatibilidad: np.random.integers -> np.random.randint\")\n",
    "    # Crear un alias para que las llamadas internas a 'integers' usen 'randint'.\n",
    "    np.random.integers = np.random.randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a4d9543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clap_scores(\n",
    "    results: list[MusicGenData], device=None\n",
    ") -> list[MusicGenCLAPResult]:\n",
    "    \"\"\"\n",
    "    Calcula el CLAP Score (similaridad texto-audio) usando embeddings del modelo CLAP.\n",
    "    \"\"\"\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\nUsando dispositivo: {device}\\n\")\n",
    "\n",
    "    # 1. Cargar modelo CLAP\n",
    "    clap_model = CLAP_Module(\n",
    "        enable_fusion=True,\n",
    "        amodel=\"HTSAT-base\",  # Modelo de 1024 dims, compatible con el checkpoint con los pesos.\n",
    "    )  # Activa la modalidad combinada audio-texto del modelo.\n",
    "\n",
    "    state_dict = factory.load_state_dict(laion_clap_path, map_location=device)\n",
    "    clap_model.model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    # clap_model.load_ckpt(laion_clap_path)  # Descarga y carga los pesos preentrenados.\n",
    "    clap_model.eval()  # Modo evaluaci√≥n (desactiva dropout, gradientes, etc.).\n",
    "    clap_model.to(device)\n",
    "\n",
    "    print(\"Modelo CLAP cargado correctamente.\\nCalculando CLAP Scores...\\n\")\n",
    "\n",
    "    scored: list[MusicGenCLAPResult] = []\n",
    "\n",
    "    # 2. Iterar sobre los resultados\n",
    "    for r in tqdm(results, desc=\"Procesando audios\", ncols=80):\n",
    "        try:\n",
    "            audio, sr = torchaudio.load(r.audio_path)\n",
    "            if sr != 48000:\n",
    "                audio = torchaudio.functional.resample(audio, sr, 48000)\n",
    "            audio = audio.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                audio_emb = clap_model.get_audio_embedding_from_data(\n",
    "                    audio, use_tensor=True\n",
    "                )\n",
    "                text_emb = clap_model.get_text_embedding(\n",
    "                    [r.description], use_tensor=True\n",
    "                )\n",
    "\n",
    "                audio_emb = torch.nn.functional.normalize(audio_emb, dim=-1)\n",
    "                text_emb = torch.nn.functional.normalize(text_emb, dim=-1)\n",
    "\n",
    "                score = torch.nn.functional.cosine_similarity(\n",
    "                    audio_emb, text_emb\n",
    "                ).item()\n",
    "\n",
    "            clap_score = round(float(score), 6)\n",
    "            scored.append(\n",
    "                MusicGenCLAPResult(\n",
    "                    id=r.id,\n",
    "                    taste=r.taste,\n",
    "                    description=r.description,\n",
    "                    instrument=r.instrument,\n",
    "                    audio_path=r.audio_path,\n",
    "                    clap_score=clap_score,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {r.id}: {e}\")\n",
    "\n",
    "    return scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1b1d10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando audios en: /home/juana/audio_reprompt/data/tracks/generated_base_music\n",
      "Se encontraron 100 archivos de audio.\n",
      "Preparados 100 registros para evaluaci√≥n CLAP.\n",
      "\n",
      "\n",
      "Usando dispositivo: cpu\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Aplicando parche de seguridad para cargar el checkpoint: /home/juana/audio_reprompt/models/checkpoints/music_audioset_epoch_15_esc_90.14.pt\n",
      "Modelo CLAP cargado correctamente.\n",
      "Calculando CLAP Scores...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando audios:   0%|                                | 0/100 [00:00<?, ?it/s]/home/juana/.venv311/lib64/python3.11/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/home/juana/.venv311/lib64/python3.11/site-packages/torchaudio/transforms/_transforms.py:581: UserWarning: Argument 'onesided' has been deprecated and has no influence on the behavior of this module.\n",
      "  warnings.warn(\n",
      "Procesando audios: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [02:34<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipeline completo: resultados guardados en /home/juana/audio_reprompt/data/scores/results_with_clap_weights.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. Construir lista de audios generados existentes.\n",
    "print(f\"\\nBuscando audios en: {tracks_base_data_path}\")\n",
    "audio_files = [f for f in os.listdir(tracks_base_data_path) if f.endswith(\".wav\")]\n",
    "\n",
    "if not audio_files:\n",
    "    raise FileNotFoundError(f\"No se encontraron audios en {tracks_base_data_path}\")\n",
    "\n",
    "print(f\"Se encontraron {len(audio_files)} archivos de audio.\")\n",
    "\n",
    "# Inferir metadata a partir del nombre de archivo.\n",
    "results: list[MusicGenData] = []\n",
    "for fname in audio_files:\n",
    "    audio_path = os.path.join(tracks_base_data_path, fname)\n",
    "    file_id = os.path.splitext(fname)[0]\n",
    "    taste = file_id.split(\"_\")[0] if \"_\" in file_id else \"unknown\"\n",
    "    description = f\"{taste} music, ambient for fine restaurant\"\n",
    "\n",
    "    results.append(\n",
    "        MusicGenData(\n",
    "            id=file_id,\n",
    "            taste=taste,\n",
    "            instrument=\"N/A\",\n",
    "            description=description,\n",
    "            audio_path=audio_path,\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"Preparados {len(results)} registros para evaluaci√≥n CLAP.\\n\")\n",
    "\n",
    "# 2. Calcular CLAP Scores.\n",
    "scored_results = compute_clap_scores(results, device=DEVICE)\n",
    "\n",
    "# 3. Guardar resultados.\n",
    "df = pd.DataFrame(scored_results)\n",
    "df.to_csv(data_clap_path, index=False)\n",
    "print(f\"\\nPipeline completo: resultados guardados en {data_clap_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e10b5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>instrument</th>\n",
       "      <th>taste</th>\n",
       "      <th>description</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>clap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bitter_24</td>\n",
       "      <td>N/A</td>\n",
       "      <td>bitter</td>\n",
       "      <td>bitter music, ambient for fine restaurant</td>\n",
       "      <td>/home/juana/audio_reprompt/data/tracks/generat...</td>\n",
       "      <td>0.066284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bitter_25</td>\n",
       "      <td>N/A</td>\n",
       "      <td>bitter</td>\n",
       "      <td>bitter music, ambient for fine restaurant</td>\n",
       "      <td>/home/juana/audio_reprompt/data/tracks/generat...</td>\n",
       "      <td>0.059639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bitter_13</td>\n",
       "      <td>N/A</td>\n",
       "      <td>bitter</td>\n",
       "      <td>bitter music, ambient for fine restaurant</td>\n",
       "      <td>/home/juana/audio_reprompt/data/tracks/generat...</td>\n",
       "      <td>0.051672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bitter_16</td>\n",
       "      <td>N/A</td>\n",
       "      <td>bitter</td>\n",
       "      <td>bitter music, ambient for fine restaurant</td>\n",
       "      <td>/home/juana/audio_reprompt/data/tracks/generat...</td>\n",
       "      <td>0.057970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sour_25</td>\n",
       "      <td>N/A</td>\n",
       "      <td>sour</td>\n",
       "      <td>sour music, ambient for fine restaurant</td>\n",
       "      <td>/home/juana/audio_reprompt/data/tracks/generat...</td>\n",
       "      <td>0.045256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>salty_22</td>\n",
       "      <td>N/A</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty music, ambient for fine restaurant</td>\n",
       "      <td>/home/juana/audio_reprompt/data/tracks/generat...</td>\n",
       "      <td>0.060276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bitter_19</td>\n",
       "      <td>N/A</td>\n",
       "      <td>bitter</td>\n",
       "      <td>bitter music, ambient for fine restaurant</td>\n",
       "      <td>/home/juana/audio_reprompt/data/tracks/generat...</td>\n",
       "      <td>0.071334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>sweet_02</td>\n",
       "      <td>N/A</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet music, ambient for fine restaurant</td>\n",
       "      <td>/home/juana/audio_reprompt/data/tracks/generat...</td>\n",
       "      <td>0.070615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>bitter_14</td>\n",
       "      <td>N/A</td>\n",
       "      <td>bitter</td>\n",
       "      <td>bitter music, ambient for fine restaurant</td>\n",
       "      <td>/home/juana/audio_reprompt/data/tracks/generat...</td>\n",
       "      <td>0.030150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>sweet_10</td>\n",
       "      <td>N/A</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet music, ambient for fine restaurant</td>\n",
       "      <td>/home/juana/audio_reprompt/data/tracks/generat...</td>\n",
       "      <td>0.065886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id instrument   taste                                description  \\\n",
       "0   bitter_24        N/A  bitter  bitter music, ambient for fine restaurant   \n",
       "1   bitter_25        N/A  bitter  bitter music, ambient for fine restaurant   \n",
       "2   bitter_13        N/A  bitter  bitter music, ambient for fine restaurant   \n",
       "3   bitter_16        N/A  bitter  bitter music, ambient for fine restaurant   \n",
       "4     sour_25        N/A    sour    sour music, ambient for fine restaurant   \n",
       "..        ...        ...     ...                                        ...   \n",
       "95   salty_22        N/A   salty   salty music, ambient for fine restaurant   \n",
       "96  bitter_19        N/A  bitter  bitter music, ambient for fine restaurant   \n",
       "97   sweet_02        N/A   sweet   sweet music, ambient for fine restaurant   \n",
       "98  bitter_14        N/A  bitter  bitter music, ambient for fine restaurant   \n",
       "99   sweet_10        N/A   sweet   sweet music, ambient for fine restaurant   \n",
       "\n",
       "                                           audio_path  clap_score  \n",
       "0   /home/juana/audio_reprompt/data/tracks/generat...    0.066284  \n",
       "1   /home/juana/audio_reprompt/data/tracks/generat...    0.059639  \n",
       "2   /home/juana/audio_reprompt/data/tracks/generat...    0.051672  \n",
       "3   /home/juana/audio_reprompt/data/tracks/generat...    0.057970  \n",
       "4   /home/juana/audio_reprompt/data/tracks/generat...    0.045256  \n",
       "..                                                ...         ...  \n",
       "95  /home/juana/audio_reprompt/data/tracks/generat...    0.060276  \n",
       "96  /home/juana/audio_reprompt/data/tracks/generat...    0.071334  \n",
       "97  /home/juana/audio_reprompt/data/tracks/generat...    0.070615  \n",
       "98  /home/juana/audio_reprompt/data/tracks/generat...    0.030150  \n",
       "99  /home/juana/audio_reprompt/data/tracks/generat...    0.065886  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc349566",
   "metadata": {},
   "source": [
    "Comparaci√≥n con los clap score con los pesos por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca05ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_path = PROJECT_ROOT / config.data.data_clap_path / \"results_with_clap_base.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4aeaa23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>instrument</th>\n",
       "      <th>taste</th>\n",
       "      <th>description</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>clap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sweet_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet music, ambient for fine restaurant</td>\n",
       "      <td>data/tracks/generated_base_music/sweet_01.wav</td>\n",
       "      <td>0.128623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sweet_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet music, ambient for fine restaurant</td>\n",
       "      <td>data/tracks/generated_base_music/sweet_02.wav</td>\n",
       "      <td>0.275660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sweet_03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet music, ambient for fine restaurant</td>\n",
       "      <td>data/tracks/generated_base_music/sweet_03.wav</td>\n",
       "      <td>0.195981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sweet_04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet music, ambient for fine restaurant</td>\n",
       "      <td>data/tracks/generated_base_music/sweet_04.wav</td>\n",
       "      <td>0.170296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sweet_05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet music, ambient for fine restaurant</td>\n",
       "      <td>data/tracks/generated_base_music/sweet_05.wav</td>\n",
       "      <td>0.186923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>salty_21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty music, ambient for fine restaurant</td>\n",
       "      <td>data/tracks/generated_base_music/salty_21.wav</td>\n",
       "      <td>0.084582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>salty_22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty music, ambient for fine restaurant</td>\n",
       "      <td>data/tracks/generated_base_music/salty_22.wav</td>\n",
       "      <td>-0.039007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>salty_23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty music, ambient for fine restaurant</td>\n",
       "      <td>data/tracks/generated_base_music/salty_23.wav</td>\n",
       "      <td>-0.020779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>salty_24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty music, ambient for fine restaurant</td>\n",
       "      <td>data/tracks/generated_base_music/salty_24.wav</td>\n",
       "      <td>0.015667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>salty_25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty music, ambient for fine restaurant</td>\n",
       "      <td>data/tracks/generated_base_music/salty_25.wav</td>\n",
       "      <td>0.058424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  instrument  taste                               description  \\\n",
       "0   sweet_01         NaN  sweet  sweet music, ambient for fine restaurant   \n",
       "1   sweet_02         NaN  sweet  sweet music, ambient for fine restaurant   \n",
       "2   sweet_03         NaN  sweet  sweet music, ambient for fine restaurant   \n",
       "3   sweet_04         NaN  sweet  sweet music, ambient for fine restaurant   \n",
       "4   sweet_05         NaN  sweet  sweet music, ambient for fine restaurant   \n",
       "..       ...         ...    ...                                       ...   \n",
       "95  salty_21         NaN  salty  salty music, ambient for fine restaurant   \n",
       "96  salty_22         NaN  salty  salty music, ambient for fine restaurant   \n",
       "97  salty_23         NaN  salty  salty music, ambient for fine restaurant   \n",
       "98  salty_24         NaN  salty  salty music, ambient for fine restaurant   \n",
       "99  salty_25         NaN  salty  salty music, ambient for fine restaurant   \n",
       "\n",
       "                                       audio_path  clap_score  \n",
       "0   data/tracks/generated_base_music/sweet_01.wav    0.128623  \n",
       "1   data/tracks/generated_base_music/sweet_02.wav    0.275660  \n",
       "2   data/tracks/generated_base_music/sweet_03.wav    0.195981  \n",
       "3   data/tracks/generated_base_music/sweet_04.wav    0.170296  \n",
       "4   data/tracks/generated_base_music/sweet_05.wav    0.186923  \n",
       "..                                            ...         ...  \n",
       "95  data/tracks/generated_base_music/salty_21.wav    0.084582  \n",
       "96  data/tracks/generated_base_music/salty_22.wav   -0.039007  \n",
       "97  data/tracks/generated_base_music/salty_23.wav   -0.020779  \n",
       "98  data/tracks/generated_base_music/salty_24.wav    0.015667  \n",
       "99  data/tracks/generated_base_music/salty_25.wav    0.058424  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base = pd.read_csv(data_base_path)\n",
    "df_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f9339",
   "metadata": {},
   "source": [
    "### Conclusiones:\n",
    "\n",
    "| Modelo                                   | Rango de valores             | Promedio general | Observaciones                                                           |\n",
    "| ---------------------------------------- | ---------------------------- | ---------------- | ----------------------------------------------------------------------- |\n",
    "| **Por defecto**                          | de **‚âà -0.18** a **‚âà +0.32** | **‚âà 0.06**       | Gran dispersi√≥n; algunos negativos; sensibilidad desigual por sabor.    |\n",
    "| **music_audioset_epoch_15_esc_90.14.pt** | de **‚âà 0.027** a **‚âà 0.093** | **‚âà 0.061**      | Valores m√°s homog√©neos y positivos; rango estrecho; menor variabilidad. |\n",
    "\n",
    "El modelo especializado produce scores m√°s consistentes y todos positivos, aunque de magnitud m√°s baja (‚âà0.03‚Äì0.09). Esto sugiere una calibraci√≥n diferente del espacio de embeddings: menos extremos, pero m√°s estables.\n",
    "\n",
    "El modelo especializado mejora la ‚Äúalineaci√≥n sem√°ntica global‚Äù entre texto y audio, lo que sugiere una mayor robustez perceptiva para tareas de clasificaci√≥n o evaluaci√≥n contextual (e.g., emparejar m√∫sica con conceptos).\n",
    "\n",
    "Sin embargo, el modelo base es m√°s sensible a diferencias de estilo, lo cual podr√≠a ser √∫til si se busca diferenciaci√≥n emocional m√°s marcada entre sabores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
